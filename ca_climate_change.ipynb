{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Install and import Library<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install pandas openpyxl\n",
    "%pip install seaborn\n",
    "%pip install shapely\n",
    "%pip install geodatasets\n",
    "%pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "import geodatasets\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> ETL - Load, transform and save data to SQL database <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upzip geojson file \n",
    "zip_file_path = 'Resources/California_Fire_Perimete.geojson.zip'\n",
    "\n",
    "# Open the zip file in read mode\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents of the zip file\n",
    "    zip_ref.extractall('Resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wildfire Data\n",
    "# Name of the geojson file\n",
    "file_js = Path('Resources/California_Fire_Perimete.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Wildfire GeoJSON Data\n",
    "wildfire_gdf = gpd.read_file(file_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID   YEAR_ STATE AGENCY UNIT_ID  FIRE_NAME   INC_NUM  \\\n",
      "0         1  2023.0    CA    CDF     SKU  WHITWORTH  00004808   \n",
      "1         2  2023.0    CA    LRA     BTU     KAISER  00010225   \n",
      "2         3  2023.0    CA    CDF     AEU    JACKSON  00017640   \n",
      "3         4  2023.0    CA    CDF     AEU     CARBON  00018821   \n",
      "4         5  2023.0    CA    CDF     AEU    LIBERTY  00018876   \n",
      "\n",
      "                      ALARM_DATE                      CONT_DATE  CAUSE  \\\n",
      "0  Sat, 17 Jun 2023 00:00:00 GMT  Sat, 17 Jun 2023 00:00:00 GMT    5.0   \n",
      "1  Fri, 02 Jun 2023 00:00:00 GMT  Fri, 02 Jun 2023 00:00:00 GMT    5.0   \n",
      "2  Sat, 01 Jul 2023 00:00:00 GMT  Sun, 02 Jul 2023 00:00:00 GMT    2.0   \n",
      "3  Tue, 11 Jul 2023 00:00:00 GMT  Tue, 11 Jul 2023 00:00:00 GMT    9.0   \n",
      "4  Tue, 11 Jul 2023 00:00:00 GMT  Wed, 12 Jul 2023 00:00:00 GMT   14.0   \n",
      "\n",
      "   C_METHOD  OBJECTIVE  GIS_ACRES COMMENTS COMPLEX_NAME  \\\n",
      "0       1.0        1.0   5.729125     None         None   \n",
      "1       1.0        1.0  13.602380     None         None   \n",
      "2       1.0        1.0  27.814460     None         None   \n",
      "3       1.0        1.0  58.760230     None         None   \n",
      "4       1.0        1.0  70.979000     None         None   \n",
      "\n",
      "                                  IRWINID FIRE_NUM COMPLEX_ID  DECADES  \\\n",
      "0  {7985848C-0AC2-4BA4-8F0E-29F778652E61}     None       None   2020.0   \n",
      "1  {43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}     None       None   2020.0   \n",
      "2  {B64E1355-BF1D-441A-95D0-BC1FBB93483B}     None       None   2020.0   \n",
      "3  {CB41DB0A-E4B1-489D-A4EA-738F2CD6DB3B}     None       None   2020.0   \n",
      "4  {F83F70A4-07A7-40B8-BD51-10CCC1C30D63}     None       None   2020.0   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-13682443 5091132.739, -13682445.825...  \n",
      "1  POLYGON ((-13576727.142 4841226.161, -13576726...  \n",
      "2  POLYGON ((-13459243 4621236, -13458968 4621453...  \n",
      "3  POLYGON ((-13468077 4642260, -13467975 4642332...  \n",
      "4  POLYGON ((-13468418 4614853, -13468428 4614801...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the structure\n",
    "print(wildfire_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['OBJECTID', 'YEAR_', 'STATE', 'AGENCY', 'UNIT_ID', 'FIRE_NAME',\n",
      "       'INC_NUM', 'ALARM_DATE', 'CONT_DATE', 'CAUSE', 'C_METHOD', 'OBJECTIVE',\n",
      "       'GIS_ACRES', 'COMMENTS', 'COMPLEX_NAME', 'IRWINID', 'FIRE_NUM',\n",
      "       'COMPLEX_ID', 'DECADES', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Extract column names\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year Range: 1878.0 to 2023.0\n"
     ]
    }
   ],
   "source": [
    "# Check the minimum and maximum year in the dataset\n",
    "min_year = wildfire_gdf['YEAR_'].min()\n",
    "max_year = wildfire_gdf['YEAR_'].max()\n",
    "\n",
    "print(f\"Year Range: {min_year} to {max_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process Wildfire Data - Change column names\n",
    "# Rename specific columns\n",
    "wildfire_gdf = wildfire_gdf.rename(columns={\n",
    "    'OBJECTID': 'ID',\n",
    "    'YEAR_': 'Year',\n",
    "    'STATE': 'State',\n",
    "    'AGENCY': 'Agency',\n",
    "    'UNIT_ID': 'Unit ID',\n",
    "    'FIRE_NAME': 'Fire Name',\n",
    "    'INC_NUM': 'Incident Number',\n",
    "    'ALARM_DATE': 'Alarm Date',\n",
    "    'CONT_DATE': 'Containment Date',\n",
    "    'CAUSE': 'Cause',\n",
    "    'C_METHOD': 'Collection Method',\n",
    "    'OBJECTIVE': 'Management Objective',\n",
    "    'GIS_ACRES': 'GIS Acres',\n",
    "    'COMMENTS': 'Comments', \n",
    "    'COMPLEX_NAME': 'Complex Name',\n",
    "    'IRWINID': 'IRWIN ID',\n",
    "    'FIRE_NUM': 'Fire Number',\n",
    "    'COMPLEX_ID': 'Complex ID',\n",
    "    'DECADES':'Decades', \n",
    "    'geometry': 'Geometry'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['ID', 'Year', 'State', 'Agency', 'Unit ID', 'Fire Name',\n",
      "       'Incident Number', 'Alarm Date', 'Containment Date', 'Cause',\n",
      "       'Collection Method', 'Management Objective', 'GIS Acres', 'Comments',\n",
      "       'Complex Name', 'IRWIN ID', 'Fire Number', 'Complex ID', 'Decades',\n",
      "       'Geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Confirm column name changes\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only a subset of columns for analysis\n",
    "wildfire_gdf = wildfire_gdf[['ID', 'Year', 'State', 'Agency', 'Unit ID', 'Fire Name',\n",
    "    'Incident Number', 'Alarm Date', 'Containment Date', 'Cause', 'GIS Acres', \n",
    "    'Comments','Complex Name', 'Fire Number', 'Decades','Geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of each geometry (for polygons)\n",
    "wildfire_gdf['Centroid'] = wildfire_gdf['Geometry'].centroid\n",
    "\n",
    "# Extract latitude and longitude from the centroid\n",
    "wildfire_gdf['Latitude'] = wildfire_gdf['Centroid'].y\n",
    "wildfire_gdf['Longitude'] = wildfire_gdf['Centroid'].x\n",
    "\n",
    "# Convert the geometry column to WKT (Well-Known Text)\n",
    "wildfire_gdf['Geometry'] = wildfire_gdf['Geometry'].apply(lambda x: x.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check transformed data\n",
    "print(wildfire_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all columns\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the sample size\n",
    "num_records = len(wildfire_gdf)\n",
    "print(f\"Number of records: {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check fire data type\n",
    "print(wildfire_gdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform Date columns to datetime\n",
    "wildfire_gdf['Alarm Date'] = pd.to_datetime(wildfire_gdf['Alarm Date'], errors='coerce' )\n",
    "wildfire_gdf['Containment Date'] = pd.to_datetime(wildfire_gdf['Containment Date'], errors='coerce' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many dates are not valid\n",
    "invalid_dates = wildfire_gdf[wildfire_gdf['Alarm Date'].isna()]\n",
    "print(invalid_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Year Month info from Alarm Date\n",
    "wildfire_gdf['DATE'] = wildfire_gdf['Alarm Date'].dt.to_period('M').dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check fire date column\n",
    "print(wildfire_gdf['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only a subset of columns for analysis - remove geometry and centroid data which SQL can't take\n",
    "wildfire_gdf = wildfire_gdf[['ID', 'Year', 'State', 'Agency', 'Unit ID', 'Fire Name',\n",
    "    'Incident Number', 'Alarm Date', 'Containment Date', 'Cause',\n",
    "    'GIS Acres', 'Comments', 'Complex Name', 'Fire Number', 'Decades',\n",
    "    'Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to a SQL database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the GeoDataFrame to the SQLite database\n",
    "# The table name will be 'wildfires' in this example\n",
    "wildfire_gdf.to_sql('wildfires', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"GeoJSON data with latitude and longitude loaded successfully into the SQLite database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to the SQLite database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Example query: Get the first 5 records\n",
    "c.execute('SELECT * FROM wildfires LIMIT 5')\n",
    "rows = c.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite wildfire format \n",
    "#  TABLE \"wildfires\" CREATE TABLE \"wildfires\" (\n",
    "# \"ID\" INTEGER,\n",
    "#   \"Year\" REAL,\n",
    "#   \"State\" TEXT,\n",
    "#   \"Agency\" TEXT,\n",
    "#   \"Unit ID\" TEXT,\n",
    "#   \"Fire Name\" TEXT,\n",
    "#   \"Incident Number\" TEXT,\n",
    "#   \"Alarm Date\" TIMESTAMP,\n",
    "#   \"Containment Date\" TIMESTAMP,\n",
    "#   \"Cause\" REAL,\n",
    "#   \"GIS Acres\" REAL,\n",
    "#   \"Comments\" TEXT,\n",
    "#   \"Complex Name\" TEXT,\n",
    "#   \"Fire Number\" TEXT,\n",
    "#   \"Decades\" REAL,\n",
    "#   \"Latitude\" REAL,\n",
    "#   \"Longitude\" REAL\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Rainfall SF Data\n",
    "# Name of the rainfall csv file\n",
    "sf_rain= Path('Resources/sf_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_sf_rain = pd.read_csv(sf_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_sf_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Rainfall LA Data\n",
    "# Name of the rainfall csv file\n",
    "la_rain= Path('Resources/la_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_la_rain = pd.read_csv(la_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_la_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Precipitation (inches)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>26.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1897</td>\n",
       "      <td>27.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1898</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1899</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>24.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Precipitation (inches)\n",
       "0  1896                   26.42\n",
       "1  1897                   27.07\n",
       "2  1898                   17.29\n",
       "3  1899                   20.19\n",
       "4  1900                   24.48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rainfall San Diego Data\n",
    "# Name of the rainfall csv file\n",
    "sdg_rain= Path('Resources/sdg_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_sdg_rain = pd.read_csv(sdg_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_sdg_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all rainfall data\n",
    "df_rain = pd.concat([df_sf_rain, df_la_rain, df_sdg_rain], axis=0, ignore_index=True)\n",
    "df_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform date columns to the correct datetime format\n",
    "df_rain['DATE TIME']=pd.to_datetime(df_rain['DATE TIME'])\n",
    "df_rain['OBS DATE']=pd.to_datetime(df_rain['OBS DATE'])\n",
    "df_rain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with just the year and month in datetime format\n",
    "df_rain['YEAR MONTH'] = df_rain['DATE TIME'].dt.to_period('M').dt.to_timestamp()\n",
    "df_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainfall Station Geo Data\n",
    "# Name of the rainfall station geo csv file\n",
    "rainfall_station = Path('Resources/weather_station_geo.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_rain_geo = pd.read_csv(rainfall_station)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_rain_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change Rainfall Station Geo Data to be consistent with df_rain data for merge later\n",
    "df_rain_geo.columns = ['STATION NAME', 'STATION_ID', 'ELEV (FEET)', 'LATITUDE', 'LONGITUDE',\n",
    "'COUNTY', 'OPERATOR AGENCY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect mergered data\n",
    "df_precip = pd.merge(df_rain, df_rain_geo, on='STATION_ID', how = 'left')\n",
    "df_precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform date columns to the correct datetime format\n",
    "df_precip['DATE TIME']=pd.to_datetime(df_precip['DATE TIME'])\n",
    "df_precip['OBS DATE']=pd.to_datetime(df_precip['OBS DATE'])\n",
    "df_precip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with just the year and month in datetime format\n",
    "df_precip['DATE'] = df_precip['DATE TIME'].dt.to_period('M').dt.to_timestamp()\n",
    "df_precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform longtitude column from string to float\n",
    "df_precip['LONGITUDE']=df_precip['LONGITUDE'].astype('float')\n",
    "df_precip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Temperatrue Data\n",
    "sf_temp_path = Path('Resources/avg-temps-sf.csv')\n",
    "la_temp_path = Path('Resources/avg-temps-la.csv')\n",
    "sd_temp_path = Path('Resources/avg-temps-sd.csv')\n",
    "sac_temp_path = Path('Resources/avg-temps-sac.csv')\n",
    "bf_temp_path = Path('Resources/avg-temps-bf.csv')\n",
    "erk_temp_path = Path('Resources/avg-temps-erk.csv')\n",
    "ca_temp_path = Path('Resources/avg-temps-ca.csv')\n",
    "dv_temp_path = Path('Resources/avg-temps-dv.csv')\n",
    "fr_temp_path = Path('Resources/avg-temps-fr.csv')\n",
    "mo_temp_path = Path('Resources/avg-temps-mo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSVs without unnecessary rows\n",
    "sf_temps_df = pd.read_csv(sf_temp_path, skiprows=3)\n",
    "la_temps_df = pd.read_csv(la_temp_path, skiprows=3)\n",
    "sd_temps_df = pd.read_csv(sd_temp_path, skiprows=3)\n",
    "sac_temps_df = pd.read_csv(sac_temp_path, skiprows=3)\n",
    "bf_temps_df = pd.read_csv(bf_temp_path, skiprows=3)\n",
    "erk_temps_df = pd.read_csv(erk_temp_path, skiprows=3)\n",
    "ca_temps_df = pd.read_csv(ca_temp_path, skiprows=3)\n",
    "dv_temps_df = pd.read_csv(dv_temp_path, skiprows=3)\n",
    "fr_temps_df = pd.read_csv(fr_temp_path, skiprows=3)\n",
    "mo_temps_df = pd.read_csv(mo_temp_path, skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all city dfs\n",
    "cities_temps = [sf_temps_df, la_temps_df, sd_temps_df, sac_temps_df, bf_temps_df, erk_temps_df, dv_temps_df, fr_temps_df, mo_temps_df, ca_temps_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime format and split year and month into two columns, then drop 'Date' column\n",
    "for city in cities_temps:\n",
    "    city['Date'] = pd.to_datetime(city['Date'], format='%Y%m')\n",
    "    city['Month'] = city['Date'].dt.month\n",
    "    city['Year'] = city['Date'].dt.year\n",
    "    city = city.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename each 'Value' column to 'Temperatrue'\n",
    "sf_temps_df = sf_temps_df.rename(columns={'Value': 'Temperatrue'})\n",
    "la_temps_df = la_temps_df.rename(columns={'Value': 'Temperatrue'})     \n",
    "sd_temps_df = sd_temps_df.rename(columns={'Value': 'Temperatrue'})     \n",
    "sac_temps_df = sac_temps_df.rename(columns={'Value': 'Temperatrue'})     \n",
    "bf_temps_df = bf_temps_df.rename(columns={'Value': 'Temperatrue'})     \n",
    "erk_temps_df = erk_temps_df.rename(columns={'Value': 'Temperatrue'}) \n",
    "ca_temps_df = ca_temps_df.rename(columns={'Value': 'Temperatrue'})  \n",
    "dv_temps_df = dv_temps_df.rename(columns={'Value': 'Temperatrue'})     \n",
    "fr_temps_df = fr_temps_df.rename(columns={'Value': 'Temperatrue'}) \n",
    "mo_temps_df = mo_temps_df.rename(columns={'Value': 'Temperatrue'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder each df\n",
    "sf_temps_df = sf_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "la_temps_df = la_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "sd_temps_df = sd_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "sac_temps_df = sac_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "bf_temps_df = bf_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "erk_temps_df = erk_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "ca_temps_df = ca_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "dv_temps_df = dv_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "fr_temps_df = fr_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]\n",
    "mo_temps_df = mo_temps_df[['Date', 'Year', 'Month', 'Temperatrue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each df\n",
    "print(sf_temps_df)\n",
    "print(la_temps_df)\n",
    "print(sd_temps_df)\n",
    "print(sac_temps_df)\n",
    "print(bf_temps_df)\n",
    "print(erk_temps_df)\n",
    "print(ca_temps_df)\n",
    "print(dv_temps_df)\n",
    "print(fr_temps_df)\n",
    "print(mo_temps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_temps_df.insert(0, 'City', 'San Francisco')\n",
    "la_temps_df.insert(0, 'City', 'Los Angeles')\n",
    "sd_temps_df.insert(0, 'City', 'San Diego')\n",
    "sac_temps_df.insert(0, 'City', 'Sacramento')\n",
    "bf_temps_df.insert(0, 'City', 'Bakersfield')\n",
    "erk_temps_df.insert(0, 'City', 'Eureka')\n",
    "ca_temps_df.insert(0, 'City', 'California')\n",
    "dv_temps_df.insert(0, 'City', 'Death Valley')\n",
    "fr_temps_df.insert(0, 'City', 'Fresno')\n",
    "mo_temps_df.insert(0, 'City', 'Modesto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the coordinates for a city:\n",
    "def get_coordinates(city_name):\n",
    "    geolocator = Nominatim(user_agent=\"wildires\")\n",
    "    location = geolocator.geocode(city_name)\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_temps = [sf_temps_df, la_temps_df, sd_temps_df, sac_temps_df, bf_temps_df, erk_temps_df, dv_temps_df, fr_temps_df, mo_temps_df]\n",
    "cities_temps_df = pd.concat(cities_temps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['San Francisco', 'Los Angeles', 'San Diego', 'Sacramento', 'Bakersfield', 'Eureka', 'California', 'Death Valley', 'Fresno', 'Modesto']\n",
    "cities_coords_df = pd.DataFrame({'City': cities})\n",
    "cities_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_coords_df[\"Latitude\"], cities_coords_df[\"Longitude\"] = zip(*cities_coords_df[\"City\"].apply(get_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_merged_df = pd.merge(cities_temps_df, cities_coords_df, on='City', how='left')\n",
    "cities_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Visualization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Wildfires per Year from 1940 to 2022\n",
    "#Objective: Visualize the trend of wildfire occurrences over the years.\n",
    "#Visualization: Line chart showing the number of wildfires per year.\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "\n",
    "# Query the database to count the number of wildfires per year\n",
    "query = \"SELECT Year, COUNT(*) as Number_of_Wildfires FROM wildfires WHERE Year >= 1940 AND Year <= 2022 GROUP BY Year ORDER BY Year\"\n",
    "wildfire_counts = pd.read_sql(query, conn)\n",
    "\n",
    "# Plot the number of wildfires per year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(wildfire_counts['Year'], wildfire_counts['Number_of_Wildfires'], marker='o')\n",
    "plt.title('Number of Wildfires per Year in California')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Wildfires')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the plot to a file  in image folder\n",
    "plt.savefig('Images/wildfires_per_year.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Acres Burned per Year from 1940 to 2022\n",
    "# Objective: Show the total area burned by wildfires each year.\n",
    "# Visualization: Bar chart displaying the total acres burned annually.\n",
    "# Connect to the SQLite database\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "\n",
    "# Query the database to sum the acres burned per year (focus on 1940 to 2020)\n",
    "query = 'SELECT Year, SUM(\"GIS Acres\") as Total_Acres_Burned FROM wildfires WHERE Year >= 1940 AND Year <= 2022 GROUP BY Year ORDER BY Year'\n",
    "acres_burned = pd.read_sql(query, conn)\n",
    "\n",
    "# Convert Year to integer\n",
    "acres_burned['Year'] = acres_burned['Year'].astype(int)\n",
    "\n",
    "# Plot the total acres burned per year\n",
    "plt.figure(figsize=(16, 8))  # Increase figure size for better readability\n",
    "sns.barplot(x='Year', y='Total_Acres_Burned', data=acres_burned, palette='OrRd')\n",
    "plt.title('Total Acres Burned per Year in California (1940-2020)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Acres Burned')\n",
    "\n",
    "# Rotate all x-axis labels to avoid overlap\n",
    "plt.xticks(rotation=45, fontsize=6)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Save the plot to a file in image folder\n",
    "plt.savefig('Images/total_acres_burned_per_year.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of Wildfire Occurrences by Month and Year\n",
    "#Objective: Understand seasonal trends in wildfire occurrences.\n",
    "#Visualization: Heatmap showing the number of wildfires by month and year.\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "\n",
    "# Query the database to get the month and year of each fire\n",
    "query = \"\"\"\n",
    "SELECT strftime('%Y', \"Alarm Date\") as Year, strftime('%m', \"Alarm Date\") as Month, COUNT(*) as Number_of_Wildfires \n",
    "FROM wildfires \n",
    "WHERE CAST(strftime('%Y', \"Alarm Date\") AS INTEGER) >= 1940 \n",
    "AND CAST(strftime('%Y', \"Alarm Date\") AS INTEGER) <= 2022 \n",
    "GROUP BY Year, Month \n",
    "ORDER BY Year, Month\n",
    "\"\"\"\n",
    "monthly_counts = pd.read_sql(query, conn)\n",
    "\n",
    "# Ensure the Month and Year columns are strings\n",
    "monthly_counts['Month'] = monthly_counts['Month'].astype(str)\n",
    "monthly_counts['Year'] = monthly_counts['Year'].astype(str)\n",
    "\n",
    "# Aggregate the data to ensure there are no duplicate Month-Year combinations\n",
    "monthly_counts_agg = monthly_counts.groupby(['Month', 'Year'], as_index=False).sum()\n",
    "\n",
    "# Pivot the data for heatmap\n",
    "monthly_counts_pivot = monthly_counts_agg.pivot(index='Month', columns='Year', values='Number_of_Wildfires')\n",
    "\n",
    "# Replace NaN values with 0 (for months/years with no wildfires)\n",
    "monthly_counts_pivot = monthly_counts_pivot.fillna(0)\n",
    "\n",
    "# Plot a heatmap of wildfire occurrences by month and year\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(monthly_counts_pivot, cmap='Reds', annot=True, annot_kws={\"size\": 6})\n",
    "plt.title('Heatmap of Wildfire Occurrences by Month and Year (1940-2022)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Month')\n",
    "# Rotate all x-axis labels to avoid overlap\n",
    "plt.xticks(rotation=45, fontsize=6)\n",
    "plt.show()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('Images/wildfire_heatmap_month_year.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wildfire Occurrences and Acreage Burned\n",
    "# Load data from the SQLite database\n",
    "conn = sqlite3.connect('ca_wildfires.db')\n",
    "wildfire_data = pd.read_sql('SELECT Year, COUNT(*) as num_fires, SUM(\"GIS Acres\") as total_acres FROM wildfires GROUP BY Year', conn)\n",
    "conn.close()\n",
    "\n",
    "# Plot wildfire occurrences and acreage burned\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Number of Fires', color='tab:orange')\n",
    "ax1.plot(wildfire_data['Year'], wildfire_data['num_fires'], color='tab:orange', label='Number of Fires')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Total Acres Burned', color='tab:red')\n",
    "ax2.plot(wildfire_data['Year'], wildfire_data['total_acres'], color='tab:red', label='Total Acres Burned')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Wildfire Occurrences and Total Acres Burned in California Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('Images/wildfire_occurence_acres_over_time.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
